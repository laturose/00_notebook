{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T10:50:31.359208Z",
     "start_time": "2018-03-13T10:50:24.141550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cubictu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/cubictu/NotebookProjects/01_sales_predict/in_path/query_result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-27d7e47b7635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/cubictu/NotebookProjects/01_sales_predict/in_path/query_result.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # single model based on t-n, t-(n-1),....ï¼Œt-1 to predict t+m  with adding more full link layer \n",
    "# ##  -- train and test\n",
    "# ##  -- add current price\n",
    "# ##  -- add dow factor\n",
    "# ##  -- production\n",
    "# ##  -- product_code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "from matplotlib import pyplot\n",
    "from numpy import concatenate\n",
    "import datetime\n",
    "import os.path\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import plotly.plotly as py\n",
    "# import plotly\n",
    "# from plotly.graph_objs import *\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plotly.tools.set_credentials_file(username='turbo_jy', api_key='4CxorJHnIRDaMqzmMp0m')\n",
    "# plotly.tools.set_config_file(world_readable=True,\n",
    "#                              sharing='public')\n",
    "# plotly.offline.init_notebook_mode() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st_time = datetime.datetime.now()\n",
    "no_epochs = 10\n",
    "limit_product_no = 1\n",
    "day_ahead = 7  #apply n days dots\n",
    "predict_lag_days = 30 # to predict the post m dot \n",
    "train_pct = 0.6\n",
    "dropout_pct = 0.3\n",
    "\n",
    "\n",
    "####2017\n",
    "result_output_path= \"/Users/cubictu/NotebookProjects/01_sales_predict/output\"\n",
    "in_path = \"/Users/cubictu/NotebookProjects/01_sales_predict/in_path\"\n",
    "\n",
    "#result_output_path= \"/home/jin.y/01_projects/01_sales_predict/outdata\"\n",
    "#in_path = \"/home/jin.y/01_projects/01_sales_predict/inputdata\"\n",
    "in_data = \"pmt_sku_ss_2016.csv\"\n",
    "model_out_path = \"/home/jin.y/01_projects/01_sales_predict/model_out\"\n",
    "\n",
    "\n",
    "for path in [result_output_path,in_path,model_out_path]:\n",
    "    if os.path.isdir(path):\n",
    "        print(\"OK\")\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(in_path+\"/\"+in_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns=[re.sub(\"pmt_sku_ss.\", \"\", col) for col in df.columns]\n",
    "columns\n",
    "df.columns = columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q = \"\"\"\n",
    "   select \n",
    "     product_code,\n",
    "     sum(case when main_prod_xssl > 0 then 1 end) as m_rt_by_0_cnt,\n",
    "     sum(main_qty) as sum_main_qty\n",
    "   from \n",
    "     df\n",
    "   group by\n",
    "     product_code\n",
    "   having sum_main_qty >= 1000\n",
    "   order by\n",
    "     m_rt_by_0_cnt desc\n",
    " \"\"\"\n",
    "df_order = sqldf(q)\n",
    "df_order.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sku_list = OrderedDict()\n",
    "for row in df_order.values:\n",
    "    sku_list[row[0]] = [row[1],row[2]]\n",
    "\n",
    "sku_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_weekofday(row):\n",
    "    dow_ind = datetime.datetime.strptime(str(row['inv_date']),'%Y%m%d').weekday()\n",
    "    return dow_ind\n",
    "\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    return agg\n",
    "\n",
    "def norm_sum(grouped):\n",
    "    if grouped['main_qty'].sum() == 0:\n",
    "        error_rate = None\n",
    "    else:\n",
    "        error_rate = grouped['diff'].sum() / grouped['main_qty'].sum()\n",
    "    return error_rate\n",
    "\n",
    "\n",
    "def cosine(grouped):\n",
    "    v1, v2 = grouped['pred_main_qty'], grouped['main_qty']\n",
    "    dist = 1 - (v1 * v2).sum() / np.sqrt((v1**2).sum() * (v2**2).sum())\n",
    "    return dist\n",
    "\n",
    "\n",
    "def load_data(fpath, cols):\n",
    "    \"\"\"\n",
    "    Load data from csv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fpath : str, file path\n",
    "    cols  : list, a list of column name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame, shape (n_samples, )\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(fpath, sep=',', header=None,\n",
    "                     names=cols)\n",
    "    df['inv_date'] = pd.to_datetime(df['inv_date'], format='%Y%m%d')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def error_measure(df, df_ref, range_day=7, metric=norm_sum):\n",
    "    \"\"\"\n",
    "    measure error using metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df      : DataFrame, df\n",
    "    df_ref  : DataFrame, reference\n",
    "    range   : int, prediction range\n",
    "    metric  : func, metric used to calculate the error/ dist\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out     : Series, error per product code\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.groupby(['product_code']).nth(list(range(range_day))).reset_index()\n",
    "    mst = df.merge(df_ref, on=['inv_date', 'product_code'], how='left')\n",
    "    mst['pred_main_qty'] = (mst['pred_sale_rate'] * mst['main_store_num_wt']).astype(int)\n",
    "    mst['diff'] = mst['pred_main_qty'] - mst['main_qty']\n",
    "    out = mst.groupby(['product_code']).apply(metric)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['dow_ind'] = df.apply(add_weekofday, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "dow_ind = df['dow_ind'].values\n",
    "dow_ind = dow_ind.reshape(dow_ind.shape[0],1)\n",
    "enc.fit(dow_ind)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dow_ind_trs = enc.transform(dow_ind).toarray()\n",
    "dow_ind_trs.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "values_add_encode_dow =  concatenate((df.values,dow_ind_trs), axis=1)\n",
    "values_add_encode_dow.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_columns = list(df.columns.values)\n",
    "new_columns.extend(['dow_1','dow_2','dow_3','dow_4','dow_5','dow_6','dow_7'])\n",
    "len(new_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(values_add_encode_dow,columns=new_columns)\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "error_dict = {}\n",
    "\n",
    "for product_no in sku_list:\n",
    "    if sku_list[product_no][0] <1000:\n",
    "        cnt = cnt + 1 \n",
    "        print(\"\"\"dealing with No.{cnt} sku : {product_no}, with points:{points} and sales:{sales}\"\"\".format(product_no = product_no\n",
    "                                                                                                   ,points = sku_list[product_no][0]\n",
    "                                                                                                  ,sales = sku_list[product_no][1]\n",
    "                                                                                                          ,cnt = cnt))\n",
    "        ####the order of inv_date and main_prod_xssl should be first column and second column\n",
    "        q =\"\"\"select\n",
    "                   inv_date,\n",
    "                   main_prod_xssl,\n",
    "                   case \n",
    "                     when main_amount*main_tag_amount>0 then main_amount/main_tag_amount\n",
    "                     else 1\n",
    "                   end as price_elastic_fac,\n",
    "                   size_num,\n",
    "                   main_size_num,\n",
    "                   qty,\n",
    "                   amount,\n",
    "                   tag_amount,\n",
    "                   in_inv,\n",
    "                   prod_xssl,\n",
    "                   main_qty,\n",
    "                   main_amount,\n",
    "                   main_tag_amount,\n",
    "                   store_num,\n",
    "                   main_store_num,\n",
    "                   dow_1,dow_2,dow_3,dow_4,dow_5,dow_6,dow_7\n",
    "                from\n",
    "                   df\n",
    "                where\n",
    "                   product_code = '{product_no}'\n",
    "               \"\"\".format(product_no = product_no)\n",
    "        df_drop_col = sqldf(q)\n",
    "    \n",
    "     \n",
    "        df_reindex = df_drop_col.set_index('inv_date' )\n",
    "        \n",
    "        ##df_reindex.head(10)\n",
    "        \n",
    "        \n",
    "        values = df_reindex.values\n",
    "        ##values.shape\n",
    "        \n",
    "        n_features = len(df_reindex.columns)\n",
    "        # frame as supervised learning\n",
    "        reframed = series_to_supervised(values, day_ahead, 1)\n",
    "        df_reframed = pd.DataFrame(reframed)\n",
    "        ##df_reframed.to_csv('{result_output_path}/out_reframed_{product_no}'.format(result_output_path= result_output_path,product_no=product_no))\n",
    "        \n",
    "        \n",
    "        ##df_reframed.shape\n",
    "        \n",
    "        ##df_reframed.head(35)\n",
    "        \n",
    "        model_master_tr1_fill_0 = df_reframed.fillna(df_reframed.mean())\n",
    "        values = model_master_tr1_fill_0.values.astype('float32')\n",
    "        \n",
    "        ###x_values_mst = values[:-(day_ahead+predict_lag_days), :-(n_features)]\n",
    "        x_values_mst = values[day_ahead:-(predict_lag_days), :-(n_features)]\n",
    "        \n",
    "        \n",
    "        ##pd.DataFrame(x_values_mst).to_csv('out')\n",
    "        ##x_values_mst.shape\n",
    "        \n",
    "        ##add other columns\n",
    "        x_values_cur_price = values[(day_ahead+predict_lag_days):,1 ]\n",
    "        \n",
    "        x_values_cur_price = x_values_cur_price.reshape(x_values_cur_price.shape[0],1)\n",
    "        \n",
    "        ##x_values_cur_price\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled = scaler.fit_transform(x_values_mst)\n",
    "        #scaled = values\n",
    "        \n",
    "        ##scaled.shape\n",
    "        \n",
    "        y_values = values[(day_ahead+predict_lag_days):, 0]\n",
    "        \n",
    "       ## y_values\n",
    "        \n",
    "        scaled.shape\n",
    "        x_values_cur_price.shape\n",
    "        \n",
    "        scaled_add_price =  concatenate((scaled,x_values_cur_price), axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_obs = int(train_pct * scaled_add_price.shape[0])\n",
    "        print(\"train_obs: {train_obs}\".format(train_obs = train_obs))\n",
    "        train_X, train_y = scaled_add_price[0:train_obs], y_values[0:train_obs]\n",
    "        test_X, test_y = scaled_add_price[train_obs:], y_values[train_obs:]\n",
    "        ##print(train_X.shape,train_y.shape)\n",
    "        ##print(test_X.shape,test_y.shape)\n",
    "        ##print(scaled_add_price.shape)\n",
    "        \n",
    "        \n",
    "        train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "        test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "        ##print(train_X.shape, train_y.shape)\n",
    "        ##print(test_X.shape, test_y.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "        # design network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(dropout_pct))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dropout(dropout_pct))\n",
    "        model.add(Dense(1, activation= None))\n",
    "        model.compile(loss='mae', optimizer='adam')\n",
    "        # fit network\n",
    "        history = model.fit(train_X, train_y, epochs=no_epochs, batch_size=30, verbose=0,shuffle=False)\n",
    "        # plot history\n",
    "        #pyplot.plot(history.history['loss'], label='train')\n",
    "        #pyplot.plot(history.history['val_loss'], label='test')\n",
    "        #pyplot.legend()\n",
    "        #pyplot.show()\n",
    "        \n",
    "        new_dict_display = {'train':[train_X,train_y],'test':[test_X,test_y]}\n",
    "        \n",
    "        error_dict_tmp = {}\n",
    "        for tt_ind in ['train','test']:\n",
    "            X = new_dict_display[tt_ind][0]\n",
    "            y = new_dict_display[tt_ind][1]\n",
    "            \n",
    "        \n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            ##yhat.shape\n",
    "            \n",
    "            ##y.shape\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_bk = X.reshape((X.shape[0], X.shape[2]))\n",
    "            \n",
    "            \n",
    "            inv_yhat_new = scaler.inverse_transform(X_bk[:,0:-1])\n",
    "            \n",
    "            \n",
    "            ##inv_yhat_new.shape\n",
    "            \n",
    "            pd.DataFrame(inv_yhat_new).head(10)\n",
    "            \n",
    "            y_1 = y.reshape(y.shape[0],1)\n",
    "            \n",
    "            out = concatenate((inv_yhat_new,y_1,yhat), axis=1)\n",
    "        \n",
    "              \n",
    "            \n",
    "            pd.DataFrame(out).to_csv(\"\"\"{result_output_path}/out_master_{product_no}_{tt_ind}\"\"\".format(product_no = product_no\n",
    "                                                                                                        ,tt_ind=tt_ind\n",
    "                                                                                                       ,result_output_path=result_output_path))\n",
    "            \n",
    "            df_plot = pd.DataFrame(out[:,-2:],columns=['actual', 'predict'])\n",
    "            \n",
    "            sum_error = 0\n",
    "            for row in df_plot.values:\n",
    "                error = abs(row[1] - row[0])**2\n",
    "                sum_error = sum_error + error\n",
    "            mean_error = sum_error**0.5 /  df_plot.values.shape[0]\n",
    "            print(\"{tt_ind}, mean_error: {mean_error}\".format(mean_error = mean_error,tt_ind = tt_ind))\n",
    "            print(\"-\"*20)\n",
    "            sku_list[product_no].append(mean_error)\n",
    "            \n",
    "            error_check_tmp = df_drop_col.iloc[predict_lag_days:-day_ahead,][['inv_date','main_prod_xssl']]\n",
    "            error_check = error_check_tmp.iloc[0:train_obs,] if tt_ind == 'train' else error_check_tmp.iloc[train_obs:,]\n",
    "                    \n",
    "            #print(\"error_check.shape:{shape}\".format(shape = error_check.shape))\n",
    "            #print(\"df_plot.shape:{shape}\".format(shape = df_plot.shape))\n",
    "            \n",
    "            new_lst=[]\n",
    "            for a,b in zip(error_check.values,df_plot.values):\n",
    "                tmp = np.append(a,b)\n",
    "                tmp = np.append(product_no,tmp)\n",
    "                new_lst.append(tmp)\n",
    "            error_check_df = pd.DataFrame(new_lst,columns=['prodcut_code','inv_date','main_prod_xssl','actual_main_sales_rt', 'predict_main_sales_rt'])\n",
    "\n",
    "            def format_trs(row):\n",
    "                return row['inv_date'].replace('.0','')\n",
    "\n",
    "            error_check_df['inv_date'] = error_check_df.apply(format_trs,axis=1)\n",
    "\n",
    "            error_check_df.to_csv(\"\"\"{result_output_path}/out_errorcheck_{product_no}_{tt_ind}\"\"\".format(product_no = product_no\n",
    "                                                                                                         ,tt_ind=tt_ind\n",
    "                                                                                                        ,result_output_path=result_output_path),\n",
    "                                 header = 0,index=0)\n",
    "            data_col = ['product_code','inv_date',  'main_sale_rate', 'abandon', 'pred_sale_rate']\n",
    "            ref_col = ['inv_date', 'product_code', 'main_store_num_wt', 'main_qty']\n",
    "\n",
    "\n",
    "            data_path=\"\"\"{result_output_path}/out_errorcheck_{product_no}_{tt_ind}\"\"\".format(product_no = product_no\n",
    "                                                                                    ,tt_ind=tt_ind\n",
    "                                                                                ,result_output_path=result_output_path)\n",
    "\n",
    "            error_check_df_tmp = load_data(data_path, data_col)\n",
    "\n",
    "            df_ref = load_data(in_path+\"/\"+\"lstm_ref_all.csv\", ref_col)\n",
    "\n",
    "            mst = []\n",
    "            measure_range = [7, 14, 30]\n",
    "\n",
    "\n",
    "            for after in measure_range:\n",
    "                tmp =  error_measure(error_check_df_tmp, df_ref, range_day=after, metric=norm_sum)\n",
    "                mst.append(tmp)\n",
    "\n",
    "            mst = pd.concat(mst, 1)\n",
    "            mst.columns = measure_range\n",
    "            error_dict_tmp[tt_ind] = [i for i in mst.values[0]]\n",
    "            error_dict[product_no] = error_dict_tmp\n",
    "\n",
    "\n",
    "#####################plot with plotly         \n",
    "#             pd_data = [\n",
    "#                 go.Scatter(\n",
    "                   \n",
    "#                     y=df_plot['actual'],\n",
    "#                     name='actual'\n",
    "#                 ),\n",
    "#                 go.Scatter(\n",
    "#                     y=df_plot['predict'],\n",
    "#                     name='predict'\n",
    "#                 )\n",
    "#             ]            \n",
    "            \n",
    "#             #py.iplot(pd_data, filename=\"\"\"{product_no}\"\"\".format(product_no = product_no),title = mean_error )\n",
    "#             layout = go.Layout(title=mean_error, width=1024, height=640)\n",
    "#             fig = go.Figure(data=pd_data, layout=layout)\n",
    "#             py.image.save_as(fig,format='png', filename=\"\"\"/Users/polaris/Desktop/a/{product_no}_{tt_ind}\"\"\".format(tt_ind=tt_ind,product_no = str(int(product_no))))\n",
    "\n",
    "\n",
    "####################plot with matplotlib\n",
    "            df_plot.plot()\n",
    "            plt.title('{product_no}_{tt_ind}, mean_error:{mean_error}'.format(product_no = product_no, mean_error = str([round(i,4) for i in error_dict_tmp[tt_ind]]),tt_ind=tt_ind)) \n",
    "            plt.savefig(\"{result_output_path}/{product_no}_{tt_ind}\".format(product_no=product_no,\n",
    "                                                                tt_ind = tt_ind,\n",
    "                                                                           result_output_path=result_output_path))\n",
    "            model.save(model_out_path+\"/\"+product_no)\n",
    "    \n",
    "\n",
    "        print(\"*\"*60)\n",
    "        print(\" \")\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    if cnt >= limit_product_no:break\n",
    "        \n",
    "print(\"finish\")\n",
    "ed_time = datetime.datetime.now()\n",
    "print(sku_list)\n",
    "print(\"*\"*20)\n",
    "print(error_dict)\n",
    "print(\"\"\"run duration:{time_dur}\"\"\".format(time_dur = int((ed_time-st_time).seconds / 60)))\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in error_dict:\n",
    "    print(i,error_dict[i]['test'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
